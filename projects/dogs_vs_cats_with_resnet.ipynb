{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ===========\n",
    "# 1. Enable data aug with tfms_side_on, etc and precompute = True\n",
    "# 2. Use lr_find() to find the highest learning rate\n",
    "# 3. Train last layer\n",
    "# 4. Train last layer with data aug\n",
    "# 5. Unfreeze layers with learn.unfreeze()\n",
    "# 6. Set layers to 3-10 times lower learning rate for earlier layers with np array\n",
    "#     1. Ex: lr=np.array([1e-4,1e-3,1e-2])\n",
    "# 7. Use lr_find() again\n",
    "# 8. Train network with cycle_mult = 2 until it overfits\n",
    "# ===========\n",
    "\n",
    "%reload ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.torch_imports import *\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *\n",
    "\n",
    "torch.cuda.set_device(1)\n",
    "\n",
    "PATH = \"data/dogbreed\"\n",
    "sz = 224 #image size\n",
    "arch = resnext101_64 #use resnext50 for better results\n",
    "bs = 58 #batch size\n",
    "\n",
    "label_csv = f'{PATH}labels.csv'\n",
    "n = len(list(open(label_csv)))-1\n",
    "val_idxs = get_cv_idxs(n) #returns around 20% of rows for a validation set since we dont have one\n",
    "\n",
    "!ls {PATH} #It turns out that the train file is not sorted into dogs, cats, etc. Instead we have a csv with all the types\n",
    "label_df = pd.read_csv(label_csv) #Pandas function for reading csvs\n",
    "label_df.head() #Gets the first row of csv\n",
    "\n",
    "# ===========\n",
    "# This df.head returns this sort of table:\n",
    "# {row_num} {ID} {Breed}\n",
    "# ===========\n",
    "\n",
    "label_df.pivot_table(index = 'breed', aggfunc = len).sort_values('id', ascending = False) #Sorts this into how many of each breed (this is \twhy we have aggfunc)\n",
    "\n",
    "# ~~~~~~~~~~~~\n",
    "# We then find out that there are 120 breeds since there are 120 rows\n",
    "# ~~~~~~~~~~~~\n",
    "\n",
    "tfms = tfms_from_model(arch, sz, aug_tfms = transforms_side_on, max_zoom = 1.1) #Pictures of dogs so we do side_on. Max_zoom is  \tfor data augs\n",
    "data = ImageClassifierData.from_csv(PATH, 'train', f'{PATH}labels.csv, test_name = 'test', val_idxs = val_idxs, suffix = '.jpg', tfms = tfms, \tbs = bs)\n",
    "fn = PATH+data.trn_ds.fnames[0]; fn\n",
    "img = PIL.image.open(fn); img\n",
    "img.size\n",
    "\n",
    "size_d = {k: PIL.image.open(PATH+k).size for k in data.trn_ds.fnames} #Dict maps name to filenames array\n",
    "row_sz, col_sz = list(zip(*size_d.values()))\n",
    "row_sz = np.array(row_sz); col_sz = np.array(col_sz)\n",
    "row_sz[:5] #First 5 rows\n",
    "plt.hist(row_sz);\n",
    "plt.hist(row_sz[row_sz<1000]) #np slicing to get row sizes less than 1000\n",
    "plt.hist(col_sz);\n",
    "len(data.trn_ds), len(data.test_ds)\n",
    "len(data.classes), data.classes[:5]\n",
    "\n",
    "def get_data(sz, bs):\n",
    "    tfms = tfms_from_model(arch, sz, aug_tfms = transforms_side_on, max_zoom = 1.1) #Pictures of dogs so we do side_on. Max_zoom \t\tis  for data augs\n",
    "    data = ImageClassifierData.from_csv(PATH, 'train', f'{PATH}labels.csv, test_name = 'test', val_idxs = val_idxs, suffix = '.jpg', tfms = \t\ttfms, bs = bs)\n",
    "    return data if sz>300 else data.resize(340, 'tmp')\n",
    "\n",
    "# ===========\n",
    "# PRECOMPUTE\n",
    "# ===========\n",
    "\n",
    "data = get_data(sz, bs)\n",
    "learn = ConvLearner.pretrained(arch, data, precompute = True) #sets up model\n",
    "lrf = learn.lr_find()\n",
    "learn.fit(1e-2, 5) #does the learning\n",
    "\n",
    "learn.precompute = False\n",
    "learn.fit(1e-2, 5, cycle_len = 1)\n",
    "learn.save('224_pre')\n",
    "learn.load('224_pre')\n",
    "\n",
    "learn.unfreeze()\n",
    "lr = np.array([1e-4, 1e-3, 1e-2]) #Differential learning rates\n",
    "learn.fit(lr, 3, cycle_len = 1)\n",
    "\n",
    "learn.set_data(get_data(299, bs)) #increase image size\n",
    "learn.freeze()\n",
    "\n",
    "learn.fit(1e-2, 3, cycle_len = 1, cycle_mult = 2) #runs first cycle once, second twice, third 4 times, etc. This increases validation accuracy\n",
    "log_preds, y= learn.TTA() #assigns first element to log_preds and second to y\n",
    "probs = np.exp(log_preds)\n",
    "accuracy(log_preds, y), metrics.log_loss(y, probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
